defaults:
  - _self_
  - scene: hm3d_00217
  - override hydra/launcher: submitit_slurm
  - override hydra/sweeper: nevergrad

project: grid_lf_hparam_search_3
deterministic_id: false
device: cuda
use_cache: true
point_batch_size: 12544

# Model specs
model_type: hash
num_grid_levels: 18
level_dim: 8  # So total dimension 256
per_level_scale: 2
mlp_depth: 1
mlp_width: 600
log2_hashmap_size: 20
resume_if_possible: false

seed: 42
epochs: 50
exp_decay_coeff: 0.5
image_to_label_loss_ratio: 1.0
label_to_image_loss_ratio: 0.1
instance_loss_scale: 100.0
label_voxel_count: 3e6
dataparallel: false
num_workers: 10

# Number of ground truth labeled images
num_inst_segmented_images: 5
num_sem_segmented_images: 96
num_web_segmented_images: 135
gt_segmentation_baseline: false
use_lseg: true
use_extra_classes: true
use_gt_classes_in_detic: true
eval_only_on_seen_inst: true
gt_semantic_weight: 10.0
exclude_diffuse_classes_in_test: true
semantic_class_remapping_in_test: false

# Cache only runs are for building per-dataset caches, which can be used for multi-run later.
cache_only_run: false

# Learning rate data
lr: 1e-4
weight_decay: 0.01
betas:
  - 0.9
  - 0.999

save_directory: "lf_hparams/{}/${scene.image_size}_px_${num_inst_segmented_images}_${num_sem_segmented_images}_${num_web_segmented_images}"

web_models:
  clip: "ViT-B/32"
  sentence: "all-mpnet-base-v2"

hydra:
  job:
    name: ${scene.base}
  callbacks:
    log_job_return:
      _target_: hydra.experimental.callbacks.LogJobReturnCallback
  run:
    dir: outputs/${scene.base}/${now:%Y-%m-%d}/${now:%H-%M-%S}_${num_inst_segmented_images}_${num_sem_segmented_images}_${num_web_segmented_images}
  sweep:
    dir: multirun/${scene.base}/${now:%Y-%m-%d}/${now:%H-%M-%S}_${num_inst_segmented_images}_${num_sem_segmented_images}_${num_web_segmented_images}
  sweeper:
    # params:
    #   # scene: hm3d_00250,hm3d_00263,hm3d_00179,hm3d_00217,hm3d_00582,hm3d_00706
    #   scene: apt_0,apt_2
    #   num_sem_segmented_images: 0,48
    #   num_web_segmented_images: 0,135
    # params:
    #   scene: hm3d_00217
    optim:
      optimizer: OnePlusOne
      budget: 120
      num_workers: 10
    parametrization:
      # num_grid_levels:
      #   init: 18
      #   lower: 14
      #   upper: 20
      #   integer: True
      # level_dim:
      #   - 2
      #   - 4
      #   - 8
      # mlp_width:
      #   init: 385
      #   step: 2
      #   lower: 32
      #   upper: 2048
      #   integer: True
      #   log: True
      # mlp_depth:
      #   init: 2
      #   lower: 1
      #   upper: 5
      #   step: 1
      #   integer: True
      # log2_hashmap_size:
      #   init: 19
      #   lower: 12
      #   upper: 20
      #   step: 1
      #   integer: True
      # state_prior.embd_pdrop:
      #   init: 0.1
      #   lower: 0.0
      #   upper: 1.0
      #   step: 0.1
      batch_size:
        init: 12544
        lower: 128
        upper: 12544
        integer: True
        log: True
      lr:
        init: 1e-4
        lower: 1e-6
        upper: 1e-1
        log: true
      weight_decay:
        init: 0.01
        lower: 0.0
        upper: 1.0
      epochs:
        init: 100
        lower: 10
        upper: 200
        step: 10
        integer: True
      # action_ae.num_bins:
      #   init: 64
      #   lower: 32
      #   upper: 256
      #   step: 2
      #   integer: True
      #   log: True
      # num_prior_epochs:
      #   init: 50
      #   lower: 30
      #   upper: 400
      #   integer: True
      #   log: True
  
  launcher:
    timeout_min: 320
    # timeout_min: 60
    cpus_per_task: 10
    gpus_per_node: 1
    tasks_per_node: 1
    mem_gb: 128
    nodes: 1
    name: ${hydra.job.name}
    _target_: hydra_plugins.hydra_submitit_launcher.submitit_launcher.SlurmLauncher
    signal_delay_s: 120
    max_num_timeout: 10
    additional_parameters: {}
    array_parallelism: 256
    setup: null
    # partition: scavenge
    partition: learnfair
