defaults:
  - _self_
  - scene: hm3d_00706
  - override hydra/launcher: submitit_slurm

project: grid_lf_high_width
device: cuda
use_cache: True
point_batch_size: 12544

# Model specs
model_type: hash
num_grid_levels: 16
level_dim: 8  # So total dimension 128

seed: 42
epochs: 205
exp_decay_coeff: 0.5
image_to_label_loss_ratio: 1.0
label_to_image_loss_ratio: 0.03
instance_loss_scale: 100.0
label_voxel_count: 3e6
dataparallel: false
num_workers: 10

# Number of ground truth labeled images
num_inst_segmented_images: 5
num_sem_segmented_images: 96
num_web_segmented_images: 135
gt_segmentation_baseline: false
gt_semantic_weight: 34.0
deterministic_id: true 

# Cache only runs are for building per-dataset caches, which can be used for multi-run later.
cache_only_run: false

# Learning rate data
lr: 1e-4
weight_decay: 0.01
betas:
  - 0.9
  - 0.999

save_directory: "lf_high_width/{}/${scene.image_size}_px_${num_inst_segmented_images}_${num_sem_segmented_images}_${num_web_segmented_images}"

web_models:
  clip: "ViT-B/32"
  sentence: "all-mpnet-base-v2"

hydra:
  job:
    name: ${project}
  callbacks:
    log_job_return:
      _target_: hydra.experimental.callbacks.LogJobReturnCallback
  run:
    dir: outputs/${scene.base}/${now:%Y-%m-%d}/${now:%H-%M-%S}_${num_inst_segmented_images}_${num_sem_segmented_images}_${num_web_segmented_images}
  sweep:
    dir: multirun/${scene.base}/${now:%Y-%m-%d}/${now:%H-%M-%S}_${num_inst_segmented_images}_${num_sem_segmented_images}_${num_web_segmented_images}
  sweeper:
    params:
      scene: hm3d_00250,hm3d_00263,hm3d_00179,hm3d_00217,hm3d_00582,hm3d_00706
      # scene: hm3d_00263,hm3d_00179
      # num_sem_segmented_images: 0
      # num_sem_segmented_images: 0,6,24,96
      num_sem_segmented_images: 0,96
      num_web_segmented_images: 0,135
  
  launcher:
    # timeout_min: 220
    timeout_min: 10
    cpus_per_task: 10
    gpus_per_node: 1
    tasks_per_node: 1
    mem_gb: 128
    nodes: 1
    name: ${hydra.job.name}
    _target_: hydra_plugins.hydra_submitit_launcher.submitit_launcher.SlurmLauncher
    signal_delay_s: 120
    max_num_timeout: 10
    additional_parameters: {}
    array_parallelism: 256
    setup: null
    # partition: scavenge
    partition: learnfair
