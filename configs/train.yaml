defaults:
  - _self_
  - scene: hm3d_00217
  - override hydra/launcher: submitit_slurm

project: grid_lf_seed
deterministic_id: true
device: cuda
use_cache: true
point_batch_size: 12544

# Model specs
model_type: hash
num_grid_levels: 18
level_dim: 8  # So total dimension 256
per_level_scale: 2
mlp_depth: 1
mlp_width: 600
log2_hashmap_size: 20

seed: 42
epochs: 150
exp_decay_coeff: 0.5
image_to_label_loss_ratio: 1.0
label_to_image_loss_ratio: 0.1
instance_loss_scale: 100.0
label_voxel_count: 3e6
dataparallel: false
num_workers: 10

# Number of ground truth labeled images
num_inst_segmented_images: 5
num_sem_segmented_images: 96
num_web_segmented_images: 135
gt_segmentation_baseline: false
use_lseg: true
use_extra_classes: true
use_gt_classes_in_detic: true
gt_semantic_weight: 10.0
eval_only_on_seen_inst: true
exclude_diffuse_classes_in_test: true
semantic_class_remapping_in_test: false

# Cache only runs are for building per-dataset caches, which can be used for multi-run later.
cache_only_run: false

# Learning rate data
lr: 1e-4
weight_decay: 0.003
betas:
  - 0.9
  - 0.999

save_directory: "lf_seed/{}/${scene.image_size}_px_${num_inst_segmented_images}_${num_sem_segmented_images}_${num_web_segmented_images}"

web_models:
  clip: "ViT-B/32"
  sentence: "all-mpnet-base-v2"

hydra:
  job:
    name: ${scene.base}
  callbacks:
    log_job_return:
      _target_: hydra.experimental.callbacks.LogJobReturnCallback
  run:
    dir: outputs/${scene.base}/${now:%Y-%m-%d}/${now:%H-%M-%S}_${num_inst_segmented_images}_${num_sem_segmented_images}_${num_web_segmented_images}
  sweep:
    dir: multirun/${scene.base}/${now:%Y-%m-%d}/${now:%H-%M-%S}_${num_inst_segmented_images}_${num_sem_segmented_images}_${num_web_segmented_images}
  sweeper:
    params:
      scene: hm3d_00250,hm3d_00263,hm3d_00179,hm3d_00217,hm3d_00582,hm3d_00706
      num_sem_segmented_images: 0,48,96
      num_web_segmented_images: 0,135
  
  launcher:
    timeout_min: 315
    # timeout_min: 60
    cpus_per_task: 10
    gpus_per_node: 1
    tasks_per_node: 1
    mem_gb: 128
    nodes: 1
    name: ${hydra.job.name}
    _target_: hydra_plugins.hydra_submitit_launcher.submitit_launcher.SlurmLauncher
    signal_delay_s: 120
    max_num_timeout: 10
    additional_parameters: {}
    array_parallelism: 256
    setup: null
    # partition: scavenge
    partition: learnfair
